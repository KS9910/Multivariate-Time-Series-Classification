{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNc/FXr/N5SXeiaTbIryNFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KS9910/Multivariate-Time-Series-Classification/blob/main/EEG_Labelling%26GAF_reducer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr8be-FJGR2c",
        "outputId": "373e6cde-4dff-4d0e-db0c-65b4881c9e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.datasets import eegbci\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "\n",
        "#Define the parameters\n",
        "subject = 1  # use data from subject 1\n",
        "hand_img_runs = [4, 8, 12]  # hand runs\n",
        "feet_img_runs = [6, 10, 14]  # feet runs\n",
        "hand_exe_runs = [3, 7, 11]  # hand runs\n",
        "feet_exe_runs = [5, 9, 13]  # feet runs\n",
        "hand_img_files = eegbci.load_data(subject, hand_img_runs, '../datasets/')\n",
        "feet_img_files = eegbci.load_data(subject, feet_img_runs, '../datasets/')\n",
        "hand_exe_files = eegbci.load_data(subject, hand_exe_runs, '../datasets/')\n",
        "feet_exe_files = eegbci.load_data(subject, feet_exe_runs, '../datasets/')\n"
      ],
      "metadata": {
        "id": "rSJiV8GJGbdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read raw data files where each file contains a run\n",
        "hand_img_raws = [read_raw_edf(f, preload=True) for f in hand_img_files]\n",
        "hand_exe_raws = [read_raw_edf(f, preload=True) for f in hand_exe_files]\n",
        "feet_img_raws = [read_raw_edf(f, preload=True) for f in feet_img_files]\n",
        "feet_exe_raws = [read_raw_edf(f, preload=True) for f in feet_exe_files]\n",
        "#Combine all loaded runs\n",
        "hand_img_obj = concatenate_raws(hand_img_raws)\n",
        "hand_exe_obj = concatenate_raws(hand_exe_raws)\n",
        "feet_img_obj = concatenate_raws(feet_img_raws)\n",
        "feet_exe_obj = concatenate_raws(feet_exe_raws)"
      ],
      "metadata": {
        "id": "4ot6aCGLGfXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a75f0f4-8b95-4037-ffdf-be33fcf6169e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_data = feet_exe_obj.get_data()\n",
        "# # OR\n",
        "# # raw_data = raw_obj._data\n",
        "\n",
        "# print(\"Number of channels: \", str(len(raw_data)))\n",
        "# print(\"Number of samples: \", str(len(raw_data[0])))"
      ],
      "metadata": {
        "id": "cPy6OzEaGkql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Extract events from raw data\n",
        "events_hi, event_ids_hi = mne.events_from_annotations(hand_img_obj, event_id='auto')\n",
        "events_fi, event_ids_fi = mne.events_from_annotations(feet_img_obj, event_id='auto')\n",
        "events_hx, event_ids_hx = mne.events_from_annotations(hand_exe_obj, event_id='auto')\n",
        "events_fx, event_ids_fx = mne.events_from_annotations(feet_exe_obj, event_id='auto')"
      ],
      "metadata": {
        "id": "qzKAT84hGn5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb2bed3-4047-4da0-86d4-130e256641cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmin, tmax = -1, 4  # define epochs around events (in s)\n",
        "#event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
        "\n",
        "epochs_hi = mne.Epochs(hand_img_obj, events_hi, event_ids_hi, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_fi = mne.Epochs(hand_img_obj, events_fi, event_ids_fi, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_hx = mne.Epochs(hand_exe_obj, events_hx, event_ids_hx, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_fx = mne.Epochs(hand_exe_obj, events_fx, event_ids_fx, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)"
      ],
      "metadata": {
        "id": "FgDx3nLvGq0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cd9022-f5e1-48da-fc87-00c265d07090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = np.shape(epochs_hi.events)\n",
        "n2 = np.shape(epochs_fi.events)\n",
        "n3 = np.shape(epochs_hx.events)\n",
        "n4 = np.shape(epochs_fx.events)\n",
        "n = n1[0] + n2[0] + n3[0] + n4[0]\n",
        "epoched_data_lables = []\n",
        "print(n)\n"
      ],
      "metadata": {
        "id": "p8QtI2DQG1bB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffcf559-6f7b-4ac2-a42a-7c6d62e3079c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in epochs_hi.events:\n",
        "    if a[2]==1:\n",
        "      epoched_data_lables.append(1);\n",
        "    elif a[2]==2:\n",
        "      epoched_data_lables.append(2);\n",
        "    else:\n",
        "      epoched_data_lables.append(4)\n",
        "\n",
        "# for a in epochs_fi.events:\n",
        "#   print(a[2])\n",
        "for a in epochs_fi.events:\n",
        "    if a[2]==1:\n",
        "      epoched_data_lables.append(1)\n",
        "    elif a[2]==2:\n",
        "      epoched_data_lables.append(3)\n",
        "    else:\n",
        "      epoched_data_lables.append(5)\n",
        "# print(\"changed\")\n",
        "# for a in epochs_fi.events:\n",
        "#   print(a[2])\n",
        "\n",
        "for a in epochs_hx.events:\n",
        "    if a[2]==1:\n",
        "      epoched_data_lables.append(1)\n",
        "    elif a[2]==2:\n",
        "      epoched_data_lables.append(6)\n",
        "    else:\n",
        "      epoched_data_lables.append(8)\n",
        "\n",
        "for a in epochs_fi.events:\n",
        "    if a[2]==1:\n",
        "      epoched_data_lables.append(1)\n",
        "    elif a[2]==2:\n",
        "      epoched_data_lables.append(7)\n",
        "    else:\n",
        "      epoched_data_lables.append(9)"
      ],
      "metadata": {
        "id": "57fPpo3ZG4kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for a in epoched_data_lables:\n",
        "#   print(a)\n",
        "print(len(epoched_data_lables))"
      ],
      "metadata": {
        "id": "XzItUk_CG8AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38dd0461-0d6d-4010-d60e-eec3ad741bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Access to the data\n",
        "data1 = epochs_hi._data\n",
        "data2 = epochs_fi._data\n",
        "data3 = epochs_hx._data\n",
        "data4 = epochs_fx._data\n",
        "# print(data.shape)\n",
        "# print(data[0,0,:])"
      ],
      "metadata": {
        "id": "JC9lB8OaG-Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate along the first axis (axis=0)\n",
        "resultant_data = np.concatenate((data1, data2, data3, data4), axis=0)\n",
        "\n",
        "# Check the shape of the resultant matrix\n",
        "print(f\"The shape of the resultant matrix is: {resultant_data.shape}\")"
      ],
      "metadata": {
        "id": "JabT-gCRG_sM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0567caed-3c6e-4c49-a824-bee51d6e1d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the resultant matrix is: (348, 64, 961)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_events = len(resultant_data) # or len(epochs.events)\n",
        "print(\"Number of events: \" + str(n_events))\n",
        "\n",
        "n_channels = len(resultant_data[0,:]) # or len(epochs.ch_names)\n",
        "print(\"Number of channels: \" + str(n_channels))\n",
        "\n",
        "n_times = len(resultant_data[0,0,:]) # or len(epochs.times)\n",
        "print(\"Number of time instances: \" + str(n_times))"
      ],
      "metadata": {
        "id": "LGUZv770HFjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ae084f-6fc2-4bd9-90e2-c2c3107f567f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of events: 348\n",
            "Number of channels: 64\n",
            "Number of time instances: 961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# def calculate_gaf(X):\n",
        "#     # Normalize input data to range [-1, 1]\n",
        "#     scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "#     X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "#     # Calculate the GASF for each time series\n",
        "#     n_samples, n_timepoints = X_normalized.shape\n",
        "#     gaf_matrices = []\n",
        "\n",
        "#     for i in range(n_samples):\n",
        "#         X_i = X_normalized[i].reshape(-1, 1)\n",
        "#         theta = np.arccos(X_i)\n",
        "#         gaf_matrix = np.cos(theta + theta.T)\n",
        "#         gaf_matrices.append(gaf_matrix)\n",
        "\n",
        "#     # Stack all GASF matrices along a new axis to form a 3D matrix\n",
        "#     gaf_matrices = np.stack(gaf_matrices, axis=0)\n",
        "\n",
        "#     return gaf_matrices\n",
        "\n",
        "def calculate_gadf(X):\n",
        "    # Normalize input data to range [-1, 1]\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    # Calculate the GADF for each time series\n",
        "    n_samples, n_timepoints = X_normalized.shape\n",
        "    gadf_matrices = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        X_i = X_normalized[i].reshape(-1, 1)\n",
        "        theta = np.arccos(np.clip(X_i, -1, 1))\n",
        "        gadf_matrix = np.sin(theta - theta.T)\n",
        "        gadf_matrices.append(gadf_matrix)\n",
        "\n",
        "    # Stack all GADF matrices along a new axis to form a 3D matrix\n",
        "    gadf_matrices = np.stack(gadf_matrices, axis=0)\n",
        "    return gadf_matrices\n",
        "\n",
        "    # def calculate_gaf(X):\n",
        "#     # Normalize input data\n",
        "#     scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "#     X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "#     # Calculate the GAF for each time series\n",
        "#     n_samples, n_timepoints = X_normalized.shape\n",
        "#     gaf_matrices = []\n",
        "\n",
        "#     for i in range(n_samples):\n",
        "#         X_i = X_normalized[i].reshape(-1, 1)\n",
        "#         cos_matrix = np.dot(X_i, X_i.T)\n",
        "\n",
        "#         # Clip values to ensure they fall within [-1, 1]\n",
        "#         # np.clip(cos_matrix, -1, 1, out=cos_matrix)\n",
        "\n",
        "#         # Calculate Gramian Angular Field\n",
        "#         # gaf_matrix = np.arccos(cos_matrix)\n",
        "\n",
        "#         # Append the GAF matrix to the list\n",
        "#         gaf_matrices.append(cos_matrix)\n",
        "\n",
        "#     # Stack all GAF matrices along a new axis to form a 3D matrix\n",
        "#     gaf_matrices = np.stack(gaf_matrices, axis=0)\n",
        "\n",
        "#     return gaf_matrices"
      ],
      "metadata": {
        "id": "xivkdkLvHIOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess EEG data (flatten)\n",
        "eeg_data_flat = resultant_data.reshape(-1, n_channels * n_times)\n",
        "scaler = MinMaxScaler()\n",
        "eeg_data_normalized = scaler.fit_transform(eeg_data_flat)\n",
        "print(\"eeg_data_normalized size:\", eeg_data_normalized.shape)\n",
        "temp=eeg_data_normalized[0].reshape(n_channels, n_times)\n",
        "print(\"eeg_data_normalized [0] size:\", temp.shape)\n",
        "eeg_images = []\n",
        "# Convert EEG data to images\n",
        "def process_in_batches(eeg_data_normalized, batch_size):\n",
        "    # n_samples = eeg_data_normalized.shape[0]\n",
        "    n_samples = 10;\n",
        "\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        batch = eeg_data_normalized[start:end]\n",
        "\n",
        "        for epoch_data in batch:\n",
        "            temp = epoch_data.reshape(n_channels, n_times)\n",
        "            image = calculate_gadf(temp)\n",
        "            eeg_images.append(image)\n",
        "\n",
        "        print(f\"Processed batch {start//batch_size + 1}/{(n_samples + batch_size - 1) // batch_size}\")\n",
        "\n",
        "    return eeg_images\n",
        "\n",
        "batch_size = 10  # Adjust batch size according to your memory constraints\n",
        "eeg_images = process_in_batches(eeg_data_normalized, batch_size)"
      ],
      "metadata": {
        "id": "hkjUIm2iHLMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02576c3a-7889-41ed-c30a-3a1a1c589667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eeg_data_normalized size: (348, 61504)\n",
            "eeg_data_normalized [0] size: (64, 961)\n",
            "Processed batch 1/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(eeg_images))\n",
        "eeg_images[0].shape\n",
        "# eeg_images[1][63].shape\n"
      ],
      "metadata": {
        "id": "y1DbY2q-HPjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9e01ae-208c-4ada-b8db-47fc4b673441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 961, 961)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "uuw07fYvvnJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/My Drive/gaf_images_1_20', 'wb') as f:\n",
        "#   np.save(f, eeg_images)"
      ],
      "metadata": {
        "id": "dlIbem9lwMv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "eeg_images_batch = []\n",
        "for i in range(0, len(eeg_images), 10):\n",
        "    batch = eeg_images[i:i+10]\n",
        "    eeg_images_batch.append(batch)\n",
        "# Assuming eeg_images is already prepared in the shape (348, 64, 64)\n",
        "eeg_images_1 = np.array(eeg_images[0])\n",
        "# Add padding to the second and third dimensions\n",
        "pad_width = ((0, 0), (1, 2), (1, 2))\n",
        "eeg_images_1_padded = np.pad(eeg_images_1, pad_width, mode='constant', constant_values=0)\n",
        "\n",
        "# Add a new dimension at the end to change shape from (64, 964, 964) to (64, 964, 964, 1)\n",
        "eeg_images_1_padded = np.expand_dims(eeg_images_1_padded, axis=-1)\n",
        "\n",
        "# Verify the shape\n",
        "print(\"eeg_images shape:\", eeg_images_1.shape)\n",
        "print(\"eeg_images_padded shape:\", eeg_images_1_padded.shape)\n"
      ],
      "metadata": {
        "id": "zpvP-kScrePA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9eccefe-c78a-439b-9241-2323973ac29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "1\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "2\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "3\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "4\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "5\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "6\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "7\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "8\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n",
            "9\n",
            "eeg_images shape: (64, 961, 961)\n",
            "eeg_images_padded shape: (64, 964, 964, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(eeg_images_1_padded[0])\n"
      ],
      "metadata": {
        "id": "ptefSIyFl8TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = (964, 964, 1)\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoder_input)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder Model\n",
        "autoencoder = models.Model(encoder_input, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the autoencoder\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "id": "TXX3rzqwMoYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder\n",
        "autoencoder.fit(eeg_images_1_padded, eeg_images_1_padded, epochs=4, batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "sqmOjPL9NKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the encoder model\n",
        "encoder = models.Model(encoder_input, encoded)\n",
        "encoded_images = encoder.predict(eeg_images_1_padded)\n",
        "# encoded_images = np.squeeze(encoded_images, axis=-1)\n",
        "# Verify the shape of the encoded images\n",
        "print(\"Shape of encoded images:\", encoded_images.shape)\n"
      ],
      "metadata": {
        "id": "BeWzlbPUj8Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Assuming 'eeg_images' is your original list of images with shape (64, 241, 241, 1)\n",
        "\n",
        "# pad_width = ((0, 0), (8, 7), (8, 7), (0, 0))  # Padding for each dimension\n",
        "# padded_encoded_images = np.pad(encoded_images, pad_width, mode='constant', constant_values=0)\n",
        "\n",
        "# print(\"Shape of padded images:\", padded_encoded_images.shape)  # Output: (64, 256, 256, 1)"
      ],
      "metadata": {
        "id": "4T9VB9qdHr6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "id": "416SVpz6zsHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def rnn_attention(input_tensor):\n",
        "    # Reshape input tensor to be compatible with RNN layer\n",
        "    reshaped_tensor = layers.Reshape((input_tensor.shape[1], input_tensor.shape[2] * input_tensor.shape[3]))(input_tensor)\n",
        "\n",
        "    # Apply GRU layer with return_sequences=True to get hidden states for each time step\n",
        "    gru_output = layers.GRU(64, return_sequences=True)(reshaped_tensor)\n",
        "\n",
        "    # Compute attention scores for each time step\n",
        "    attention_scores = layers.Dense(1, activation='sigmoid')(gru_output)\n",
        "\n",
        "    # Normalize attention scores using softmax\n",
        "    attention_weights = layers.Softmax()(attention_scores)\n",
        "\n",
        "    # Weighted sum of hidden states with attention weights\n",
        "    attended_features = layers.Multiply()([gru_output, attention_weights])\n",
        "\n",
        "    # Reshape to a 2D representation for further processing\n",
        "    attended_features = layers.Reshape((input_tensor.shape[1], 64))(attended_features) # Reshape to (256, 64)\n",
        "\n",
        "    return attended_features\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (241, 241, 1)  # Shape of the grayscale GAF image\n",
        "input_tensor = layers.Input(shape=input_shape)\n",
        "\n",
        "# Apply RNN attention mechanism\n",
        "attended_features = rnn_attention(input_tensor)\n",
        "\n",
        "# You might need additional layers here to process the attended_features\n",
        "# before reshaping it back to the original image dimensions if needed.\n",
        "\n",
        "# Create Keras model to use the RNN attention layer\n",
        "model = models.Model(inputs=input_tensor, outputs=attended_features)"
      ],
      "metadata": {
        "id": "v_tbNcjmyac3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_attention_image = model.predict(encoded_images)\n",
        "\n",
        "print(\"Shape of result:\", after_attention_image.shape)  # Output: (64, 256, 64)"
      ],
      "metadata": {
        "id": "Z0fnWf1dFYXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'after_attention_images' contains the images\n",
        "for i, image in enumerate(after_attention_image):\n",
        "  # plt.figure(figsize=(6, 3))\n",
        "  # plt.title(\"after_attention_image\")\n",
        "  # plt.imshow(image)\n",
        "  # plt.show()\n",
        "  # Save as PNG\n",
        "  plt.imsave(f'/content/gdrive/My Drive/GAF_image_s1_e0/image_{i}.png', image)\n",
        "\n",
        "  # Or, save as JPG\n",
        "  # plt.imsave(f'/content/gdrive/My Drive/image_{i}.jpg', image, cmap='gray')"
      ],
      "metadata": {
        "id": "XqJwJK49tmGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the original image\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(eeg_images_1_padded[0])\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Compressed image\")\n",
        "plt.imshow(encoded_images[0])\n",
        "\n",
        "# Visualize the encoded image (flattened to 1D)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"after_attention_image\")\n",
        "plt.imshow(after_attention_image[0])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eWfdEdh-4cea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create an RGB image by replicating the grayscale image across the channels\n",
        "# color_image = np.zeros((encoded_images[0].shape[0], encoded_images[0].shape[1], 3))\n",
        "# color_image[..., 0] = encoded_images[0]  # Red channel\n",
        "# color_image[..., 1] = encoded_images[0]  # Green channel\n",
        "# color_image[..., 2] = encoded_images[0]  # Blue channel\n",
        "\n",
        "# # Plot the RGB GAF image\n",
        "# plt.imshow(color_image)\n",
        "# plt.title('Gramian Angular Field as RGB Image')\n",
        "# plt.show()\n",
        "# # encoded_images[0]\n",
        "# color_image.shape"
      ],
      "metadata": {
        "id": "wP12YrFziSnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# red_image = color_image[:, :, 0]  # Add the Red component\n",
        "# green_image = color_image[:, :, 1]  # Add the Green component\n",
        "# blue_image = color_image[:, :, 2]  # Add the Blue component\n"
      ],
      "metadata": {
        "id": "bZ3iLSmAkedp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmtyIN4km6HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# matrix = color_image\n",
        "# # Normalize matrix values to the range 0 to 1\n",
        "# normalized_matrix = (matrix + 1) / 2\n",
        "\n",
        "# # Convert normalized values to the range 0 to 255\n",
        "# scaled_matrix = (normalized_matrix * 255).astype(np.uint8)\n",
        "\n",
        "# # scaled_matrix[1]\n",
        "# scaled_matrix.shape"
      ],
      "metadata": {
        "id": "tQJnM4qGNEQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create empty channel\n",
        "# empty_channel = np.zeros_like(scaled_matrix)\n",
        "# empty_channel.shape\n",
        "# # Create images for each color component\n",
        "# red_image = np.stack((scaled_matrix, empty_channel, empty_channel), axis=-1)\n",
        "# green_image = np.stack((empty_channel, scaled_matrix, empty_channel), axis=-1)\n",
        "# blue_image = np.stack((empty_channel, empty_channel, scaled_matrix), axis=-1)"
      ],
      "metadata": {
        "id": "35-yu4IKVb4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# red_image.shape\n",
        "# red_image"
      ],
      "metadata": {
        "id": "qyUSK8PLWCDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# blue_image"
      ],
      "metadata": {
        "id": "xo3WjKzEWvoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# # !pip install PIL\n",
        "# # from PIL import Image\n",
        "# # # Convert to PIL images for display or saving\n",
        "# # original_image = Image.fromarray(color_image)\n",
        "# # red_image_pil = Image.fromarray(red_image)\n",
        "# # green_image_pil = Image.fromarray(green_image)\n",
        "# # blue_image_pil = Image.fromarray(blue_image)\n",
        "\n",
        "# # Display the images\n",
        "# plt.figure(figsize=(15, 5))\n",
        "\n",
        "# plt.subplot(1, 4, 1)\n",
        "# plt.imshow(color_image,cmap='rainbow')\n",
        "# plt.title('original')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.subplot(1, 4, 2)\n",
        "# plt.imshow(red_image)\n",
        "# plt.title('Red Component')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.subplot(1, 4, 3)\n",
        "# plt.imshow(green_image)\n",
        "# plt.title('Green Component')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.subplot(1, 4, 4)\n",
        "# plt.imshow(blue_image)\n",
        "# plt.title('Blue Component')\n",
        "# plt.axis('off')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "GJoqEQ-xV7Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# # Number of epochs to display\n",
        "# num_epochs_to_display = 5\n",
        "# figsize = (10, 2 * num_epochs_to_display)\n",
        "# dpi = 100  # Default DPI\n",
        "\n",
        "# # Plot the images\n",
        "# fig, axes = plt.subplots(num_epochs_to_display, 1, figsize=figsize)\n",
        "\n",
        "# for i in range(num_epochs_to_display):\n",
        "#     axes[i].imshow(eeg_images[i][0], cmap='rainbow', origin='lower')\n",
        "#     axes[i].set_title(f\"GAF of EEG data for epoch {i}\")\n",
        "#     axes[i].set_xlabel(\"Time\")\n",
        "#     axes[i].set_ylabel(\"Channels\")\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "9m01W7MJcJnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}