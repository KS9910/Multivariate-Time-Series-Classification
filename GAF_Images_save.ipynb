{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxpZxc4UXy1EjJR0zxmlfb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KS9910/Multivariate-Time-Series-Classification/blob/main/GAF_Images_save.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JliAGmo-1spi",
        "outputId": "3e54538f-fe76-4e03-9937-39db403a9f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.datasets import eegbci\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "\n",
        "#Define the parameters\n",
        "subject = 1  # use data from subject 1\n",
        "hand_img_runs = [4, 8, 12]  # hand runs\n",
        "feet_img_runs = [6, 10, 14]  # feet runs\n",
        "hand_exe_runs = [3, 7, 11]  # hand runs\n",
        "feet_exe_runs = [5, 9, 13]  # feet runs\n",
        "hand_img_files = eegbci.load_data(subject, hand_img_runs, '../datasets/')\n",
        "feet_img_files = eegbci.load_data(subject, feet_img_runs, '../datasets/')\n",
        "hand_exe_files = eegbci.load_data(subject, hand_exe_runs, '../datasets/')\n",
        "feet_exe_files = eegbci.load_data(subject, feet_exe_runs, '../datasets/')\n"
      ],
      "metadata": {
        "id": "imWZG0ZP16Hl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read raw data files where each file contains a run\n",
        "hand_img_raws = [read_raw_edf(f, preload=True) for f in hand_img_files]\n",
        "hand_exe_raws = [read_raw_edf(f, preload=True) for f in hand_exe_files]\n",
        "feet_img_raws = [read_raw_edf(f, preload=True) for f in feet_img_files]\n",
        "feet_exe_raws = [read_raw_edf(f, preload=True) for f in feet_exe_files]\n",
        "#Combine all loaded runs\n",
        "hand_img_obj = concatenate_raws(hand_img_raws)\n",
        "hand_exe_obj = concatenate_raws(hand_exe_raws)\n",
        "feet_img_obj = concatenate_raws(feet_img_raws)\n",
        "feet_exe_obj = concatenate_raws(feet_exe_raws)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpjhGMj22A72",
        "outputId": "7519a3c4-837a-45aa-ebad-b9ab1c3dc565"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R05.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R09.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
            "Extracting EDF parameters from /datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R13.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Extract events from raw data\n",
        "events_hi, event_ids_hi = mne.events_from_annotations(hand_img_obj, event_id='auto')\n",
        "events_fi, event_ids_fi = mne.events_from_annotations(feet_img_obj, event_id='auto')\n",
        "events_hx, event_ids_hx = mne.events_from_annotations(hand_exe_obj, event_id='auto')\n",
        "events_fx, event_ids_fx = mne.events_from_annotations(feet_exe_obj, event_id='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G-Eh2fM2Nl0",
        "outputId": "06680e04-ebf9-4617-dc0c-d8de20c9d88b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
            "Used Annotations descriptions: ['T0', 'T1', 'T2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmin, tmax = -1, 4  # define epochs around events (in s)\n",
        "#event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
        "\n",
        "epochs_hi = mne.Epochs(hand_img_obj, events_hi, event_ids_hi, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_fi = mne.Epochs(hand_img_obj, events_fi, event_ids_fi, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_hx = mne.Epochs(hand_exe_obj, events_hx, event_ids_hx, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)\n",
        "epochs_fx = mne.Epochs(hand_exe_obj, events_fx, event_ids_fx, tmin - 0.5, tmax + 0.5, baseline=None, preload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_3mqCs2QQS",
        "outputId": "272c60f9-8e56-4518-e334-d28630618257"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n",
            "Not setting metadata\n",
            "90 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 90 events and 961 original time points ...\n",
            "3 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Access to the data\n",
        "data1 = epochs_hi._data\n",
        "data2 = epochs_fi._data\n",
        "data3 = epochs_hx._data\n",
        "data4 = epochs_fx._data\n",
        "# print(data.shape)\n",
        "# print(data[0,0,:])"
      ],
      "metadata": {
        "id": "2GSVlINw2Uzg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate along the first axis (axis=0)\n",
        "resultant_data = np.concatenate((data1, data2, data3, data4), axis=0)\n",
        "\n",
        "# Check the shape of the resultant matrix\n",
        "print(f\"The shape of the resultant matrix is: {resultant_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgpSmuYZ2cTV",
        "outputId": "cd77f722-80b1-4ff8-b31f-9e9998e50a24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the resultant matrix is: (348, 64, 961)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_events = len(resultant_data) # or len(epochs.events)\n",
        "print(\"Number of events: \" + str(n_events))\n",
        "\n",
        "n_channels = len(resultant_data[0,:]) # or len(epochs.ch_names)\n",
        "print(\"Number of channels: \" + str(n_channels))\n",
        "\n",
        "n_times = len(resultant_data[0,0,:]) # or len(epochs.times)\n",
        "print(\"Number of time instances: \" + str(n_times))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_Nj56t2v14",
        "outputId": "9b78c9c9-931a-426d-8f1b-90d3e53b9838"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of events: 348\n",
            "Number of channels: 64\n",
            "Number of time instances: 961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def calculate_gadf(X):\n",
        "    # Normalize input data to range [-1, 1]\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    # Calculate the GADF for each time series\n",
        "    n_samples, n_timepoints = X_normalized.shape\n",
        "    gadf_matrices = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        X_i = X_normalized[i].reshape(-1, 1)\n",
        "        theta = np.arccos(np.clip(X_i, -1, 1))\n",
        "        gadf_matrix = np.sin(theta - theta.T)\n",
        "        gadf_matrices.append(gadf_matrix)\n",
        "\n",
        "    # Stack all GADF matrices along a new axis to form a 3D matrix\n",
        "    gadf_matrices = np.stack(gadf_matrices, axis=0)\n",
        "    return gadf_matrices\n"
      ],
      "metadata": {
        "id": "hCpwHuDv2jKJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess EEG data (flatten)\n",
        "eeg_data_flat = resultant_data.reshape(-1, n_channels * n_times)\n",
        "scaler = MinMaxScaler()\n",
        "eeg_data_normalized = scaler.fit_transform(eeg_data_flat)\n",
        "print(\"eeg_data_normalized size:\", eeg_data_normalized.shape)\n",
        "temp=eeg_data_normalized[0].reshape(n_channels, n_times)\n",
        "print(\"eeg_data_normalized [0] size:\", temp.shape)\n",
        "eeg_images = []\n",
        "# Convert EEG data to images\n",
        "def process_in_batches(eeg_data_normalized, batch_size):\n",
        "    # n_samples = eeg_data_normalized.shape[0]\n",
        "    n_samples = 120;\n",
        "\n",
        "    for start in range(110, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        batch = eeg_data_normalized[start:end]\n",
        "\n",
        "        for epoch_data in batch:\n",
        "            temp = epoch_data.reshape(n_channels, n_times)\n",
        "            image = calculate_gadf(temp)\n",
        "            eeg_images.append(image)\n",
        "\n",
        "        print(f\"Processed batch {start//batch_size + 1}/{(n_samples + batch_size - 1) // batch_size}\")\n",
        "\n",
        "    return eeg_images\n",
        "\n",
        "batch_size = 10  # Adjust batch size according to your memory constraints\n",
        "eeg_images = process_in_batches(eeg_data_normalized, batch_size)\n",
        "print(len(eeg_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-IeSFgR2nmu",
        "outputId": "67343828-e624-4f75-9ca3-b7587e170cbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eeg_data_normalized size: (348, 61504)\n",
            "eeg_data_normalized [0] size: (64, 961)\n",
            "Processed batch 12/12\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = (964, 964, 1)\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoder_input)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder Model\n",
        "autoencoder = models.Model(encoder_input, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the autoencoder\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ua69ewh34Ot",
        "outputId": "7b87ba65-4c33-4dba-d2eb-02a9457eb416"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 964, 964, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 964, 964, 1)       10        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 482, 482, 1)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 482, 482, 1)       10        \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 241, 241, 1)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 241, 241, 1)       10        \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 482, 482, 1)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 482, 482, 1)       10        \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 964, 964, 1)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 964, 964, 1)       10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50 (200.00 Byte)\n",
            "Trainable params: 50 (200.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def rnn_attention(input_tensor):\n",
        "    # Reshape input tensor to be compatible with RNN layer\n",
        "    reshaped_tensor = layers.Reshape((input_tensor.shape[1], input_tensor.shape[2] * input_tensor.shape[3]))(input_tensor)\n",
        "\n",
        "    # Apply GRU layer with return_sequences=True to get hidden states for each time step\n",
        "    gru_output = layers.GRU(64, return_sequences=True)(reshaped_tensor)\n",
        "\n",
        "    # Compute attention scores for each time step\n",
        "    attention_scores = layers.Dense(1, activation='sigmoid')(gru_output)\n",
        "\n",
        "    # Normalize attention scores using softmax\n",
        "    attention_weights = layers.Softmax()(attention_scores)\n",
        "\n",
        "    # Weighted sum of hidden states with attention weights\n",
        "    attended_features = layers.Multiply()([gru_output, attention_weights])\n",
        "\n",
        "    # Reshape to a 2D representation for further processing\n",
        "    attended_features = layers.Reshape((input_tensor.shape[1], 64))(attended_features) # Reshape to (256, 64)\n",
        "\n",
        "    return attended_features\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (241, 241, 1)  # Shape of the grayscale GAF image\n",
        "input_tensor = layers.Input(shape=input_shape)\n",
        "\n",
        "# Apply RNN attention mechanism\n",
        "attended_features = rnn_attention(input_tensor)\n",
        "\n",
        "# You might need additional layers here to process the attended_features\n",
        "# before reshaping it back to the original image dimensions if needed.\n",
        "\n",
        "# Create Keras model to use the RNN attention layer\n",
        "model = models.Model(inputs=input_tensor, outputs=attended_features)"
      ],
      "metadata": {
        "id": "7x_h2bR64f3v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "eeg_images_batch = []\n",
        "for i in range(0,5):\n",
        "  # Assuming eeg_images is already prepared in the shape (348, 64, 64)\n",
        "  eeg_images_1 = np.array(eeg_images[i])\n",
        "  # Add padding to the second and third dimensions\n",
        "  pad_width = ((0, 0), (1, 2), (1, 2))\n",
        "  eeg_images_1_padded = np.pad(eeg_images_1, pad_width, mode='constant', constant_values=0)\n",
        "\n",
        "  # Add a new dimension at the end to change shape from (64, 964, 964) to (64, 964, 964, 1)\n",
        "  eeg_images_1_padded = np.expand_dims(eeg_images_1_padded, axis=-1)\n",
        "\n",
        "  # Train the autoencoder\n",
        "  autoencoder.fit(eeg_images_1_padded, eeg_images_1_padded, epochs=4, batch_size=1, shuffle=True)\n",
        "\n",
        "  # Extract the encoder model\n",
        "  encoder = models.Model(encoder_input, encoded)\n",
        "  encoded_images = encoder.predict(eeg_images_1_padded)\n",
        "  print(\"Shape of encoded images:\", encoded_images.shape)\n",
        "\n",
        "  # RNN Attention for enhancing the features of GAF images\n",
        "  after_attention_image = model.predict(encoded_images)\n",
        "  print(\"Shape of result:\", after_attention_image.shape)  # Output: (64, 256, 64)\n",
        "\n",
        "  eeg_images_batch.append(after_attention_image)\n",
        "\n",
        "# Convert the list eeg_images_batch to a NumPy array\n",
        "eeg_images_batch_array = np.array(eeg_images_batch)\n",
        "\n",
        "# saving into the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "with open('/content/gdrive/My Drive/GAF_image_s1/gaf_images_e_110-115.npy', 'wb') as f:\n",
        "  np.save(f, eeg_images_batch_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hy8uUz2-OG",
        "outputId": "ab855fa0-1c2e-4544-b0a9-e8f802871aee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "64/64 [==============================] - 6s 9ms/step - loss: 0.5698\n",
            "Epoch 2/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.4377\n",
            "Epoch 3/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.3003\n",
            "Epoch 4/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2661\n",
            "2/2 [==============================] - 1s 40ms/step\n",
            "Shape of encoded images: (64, 241, 241, 1)\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Shape of result: (64, 241, 64)\n",
            "Epoch 1/4\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.2707\n",
            "Epoch 2/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2632\n",
            "Epoch 3/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2572\n",
            "Epoch 4/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2518\n",
            "2/2 [==============================] - 0s 42ms/step\n",
            "Shape of encoded images: (64, 241, 241, 1)\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Shape of result: (64, 241, 64)\n",
            "Epoch 1/4\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.2402\n",
            "Epoch 2/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2389\n",
            "Epoch 3/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2378\n",
            "Epoch 4/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2371\n",
            "2/2 [==============================] - 0s 40ms/step\n",
            "Shape of encoded images: (64, 241, 241, 1)\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Shape of result: (64, 241, 64)\n",
            "Epoch 1/4\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.2400\n",
            "Epoch 2/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2392\n",
            "Epoch 3/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2386\n",
            "Epoch 4/4\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.2380\n",
            "2/2 [==============================] - 0s 41ms/step\n",
            "Shape of encoded images: (64, 241, 241, 1)\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Shape of result: (64, 241, 64)\n",
            "Epoch 1/4\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.2284\n",
            "Epoch 2/4\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2279\n",
            "Epoch 3/4\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.2274\n",
            "Epoch 4/4\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.2269\n",
            "2/2 [==============================] - 0s 41ms/step\n",
            "Shape of encoded images: (64, 241, 241, 1)\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Shape of result: (64, 241, 64)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now you can access the shape\n",
        "print(eeg_images_batch_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGd8fYooAxLZ",
        "outputId": "e1fc777f-148a-4de7-8c02-349b4ea909d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 64, 241, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5JXVEFr5fEn"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}